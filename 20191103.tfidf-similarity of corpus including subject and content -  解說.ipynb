{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf : 單字 在每一篇文章出現次數(每篇文章都出現airplane) 越多字 評分越高 \n",
    "# idf : inverse-df : 每一單字跨文章出現次數(越多越沒有代表性 airplane) 同一單字 跨越多篇文章 評分越低 \n",
    "# tf * idf = 數字越大越好\n",
    "#  (單字出現頻率 / 該篇有多少單字) * log( 所有文章的篇數 / 有出現幾篇)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1]\n",
      " [0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[[0.29505881 0.23262775 0.29505881 0.29505881 0.         0.\n",
      "  0.         0.         0.         0.         0.29505881 0.\n",
      "  0.         0.         0.         0.23262775 0.         0.\n",
      "  0.29505881 0.29505881 0.29505881 0.29505881 0.29505881 0.23262775\n",
      "  0.23262775]\n",
      " [0.         0.         0.         0.         0.         0.40824829\n",
      "  0.40824829 0.         0.         0.         0.         0.40824829\n",
      "  0.40824829 0.         0.40824829 0.         0.         0.40824829\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.37222485 0.         0.         0.         0.\n",
      "  0.         0.         0.47212003 0.         0.         0.\n",
      "  0.         0.         0.         0.37222485 0.47212003 0.\n",
      "  0.         0.         0.         0.         0.         0.37222485\n",
      "  0.37222485]\n",
      " [0.         0.         0.         0.         0.5        0.\n",
      "  0.         0.5        0.         0.5        0.         0.\n",
      "  0.         0.5        0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        ]]\n",
      "[0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "base = 1 # 從四篇文章中取出指定的那一篇[0, 1, 2, 3]\n",
    "#Case subject\n",
    "subject = [\n",
    "    '[OSCE XG 1876] windows 10 update 1809 asking us to uninstall trend micro',\n",
    "    'Clients Not showing online on Console',\n",
    "    '[OSCE XG] Windows feature pack 1809', \n",
    "    'I have one cute cat',\n",
    "]\n",
    "vectorizer = CountVectorizer() # 準備將文字轉換後，計算出現頻率\n",
    "X = vectorizer.fit_transform(subject)\n",
    "#word = vectorizer.get_feature_names()\n",
    "#print(word)\n",
    "print(X.toarray()) # 該部分就是 文字轉代碼，類似 影像轉代碼\n",
    "\n",
    "transformer = TfidfTransformer() # 針對每一個單字加上 weight\n",
    "tfidf = transformer.fit_transform(X)\n",
    "#np.set_printoptions(precision=5)\n",
    "print(tfidf.toarray())\n",
    "\n",
    "# 想知道每一篇文章 跟其他篇文章相似程度 以下是使用統計的方式 \n",
    "# 從已經加上weight的數據，去使用cosine similarity 去比較文章的相似度\n",
    "#cosine_similarity(tfidf[base], tfidf).ravel()\n",
    "similarity_subject = np.array(cosine_similarity(tfidf[base], tfidf)).ravel()\n",
    "print(similarity_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "base = 1 # 從四篇文章中取出指定的那一篇[0, 1, 2, 3]\n",
    "#Case subject\n",
    "subject = [\n",
    "    '[OSCE XG 1876] windows 10 update 1809 asking us to uninstall trend micro',\n",
    "    'Clients Not showing online on Console',\n",
    "    '[OSCE XG] Windows feature pack 1809', \n",
    "    'I have one cute cat',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1]\n",
      " [0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.29505881, 0.23262775, 0.29505881, 0.29505881, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.29505881, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.23262775, 0.        , 0.        , 0.29505881, 0.29505881,\n",
       "        0.29505881, 0.29505881, 0.29505881, 0.23262775, 0.23262775],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.40824829, 0.40824829, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.40824829, 0.40824829, 0.        , 0.40824829,\n",
       "        0.        , 0.        , 0.40824829, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.37222485, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.47212003, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.37222485, 0.47212003, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.37222485, 0.37222485],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.5       ,\n",
       "        0.        , 0.        , 0.5       , 0.        , 0.5       ,\n",
       "        0.        , 0.        , 0.        , 0.5       , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer() # 準備將文字轉換後，計算出現頻率\n",
    "X = vectorizer.fit_transform(subject)\n",
    "#word = vectorizer.get_feature_names()\n",
    "#print(word)\n",
    "print(X.toarray()) # 該部分就是 文字轉代碼，類似 影像轉代碼\n",
    "\n",
    "transformer = TfidfTransformer() # 針對每一個單字加上 weight\n",
    "tfidf = transformer.fit_transform(X)\n",
    "#np.set_printoptions(precision=5)\n",
    "tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.03382064 0.20835866 0.03767698]\n"
     ]
    }
   ],
   "source": [
    "#Case body\n",
    "body = [    \n",
    "    'Altaan called in regarding recent windows 10 update 1809 asking us to uninstall trend micro . Unloading agents will allow the installation of 1809 upgrade',\n",
    "    'Clients Not showing online on Console \\\\Suddenly clients on the server went 0',\n",
    "    'Windows feature pack 1809 reports an incompatibility with Trend. Forces an uninstall in order to update Windows. I then manually reinstall Trend without any issues but when manually scanning files Office scan hangs and i have to run an end task.',\n",
    "    'How is weather today in Taipei',\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(body)\n",
    "word = vectorizer.get_feature_names()\n",
    "#print(word)\n",
    "transformer = TfidfTransformer()\n",
    "tfidf = transformer.fit_transform(X)\n",
    "body_subject = np.array(cosine_similarity(tfidf[base], tfidf)).ravel()\n",
    "print(body_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.01691032, 0.277359  , 0.01883849])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = similarity_subject * 0.5 + body_subject * 0.5\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity 0.27735899520865304\n",
      "---------------------------------------------------------------\n",
      "Src Subject :  \n",
      " [OSCE XG 1876] windows 10 update 1809 asking us to uninstall trend micro\n",
      "Src Body : \n",
      " Altaan called in regarding recent windows 10 update 1809 asking us to uninstall trend micro . Unloading agents will allow the installation of 1809 upgrade\n",
      "---------------------------------------------------------------\n",
      "Prd Subject :  \n",
      " [OSCE XG] Windows feature pack 1809\n",
      "Prd Body : \n",
      " Windows feature pack 1809 reports an incompatibility with Trend. Forces an uninstall in order to update Windows. I then manually reinstall Trend without any issues but when manually scanning files Office scan hangs and i have to run an end task.\n"
     ]
    }
   ],
   "source": [
    "# 50 : 50 weight\n",
    "values = similarity_subject * 0.5 + body_subject * 0.5\n",
    "# remove myself\n",
    "\n",
    "values[base] = 0 \n",
    "# find best solution\n",
    "index = np.argmax(values)\n",
    "# print out sugesiton only similarity > 0.1\n",
    "if values[index] > 0.1:\n",
    "    print('Similarity {}'.format(values[index]))\n",
    "    print('---------------------------------------------------------------')\n",
    "    print('Src Subject : ','\\n', subject[base])\n",
    "    print('Src Body :','\\n', body[base])\n",
    "    print('---------------------------------------------------------------')\n",
    "    print('Prd Subject : ','\\n', subject[index])\n",
    "    print('Prd Body :','\\n', body[index])\n",
    "else:\n",
    "    print('Similarity {}'.format(values[index]))\n",
    "    print('NO_DATA_FOUND')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
