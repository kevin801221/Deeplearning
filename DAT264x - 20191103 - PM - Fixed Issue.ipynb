{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 套件\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from string import punctuation\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取 train data\n",
    "train = pd.read_csv('train_values.csv')\n",
    "train_label = pd.read_csv('train_labels.csv')\n",
    "test = pd.read_csv('test_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18687, 2), (18687, 25), (18699, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 檢查數據\n",
    "train.shape , train_label.shape, test.shape # 筆數正確"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拿高分的資料清除位置\n",
    "def rm_tags(text):\n",
    "    re_tag = r'<[^>]+>'\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(re_tag, '', text)\n",
    "    text = re.sub(r\"didn't\",\"did not\", text)\n",
    "    text = re.sub(r\"haven't\",\"have not\", text)\n",
    "    text = re.sub(r\"can't\",\"can not\", text)\n",
    "    text = re.sub(r\"it's\",\"it is\", text)\n",
    "    text = re.sub(r\"won't\",\"will not\", text)\n",
    "    text = re.sub(r\"wouldn't\",\"would not\",text)\n",
    "    # 請繼續加入\n",
    "    \n",
    "    text = re.sub(r\"[&-/()),%']\", ' ', text) #這特殊符號都去除\n",
    "    text = re.sub(r\"\\.\", ' ', text) # 點換成一個空白\n",
    "    text = re.sub(r\"\\s+\", ' ', text) #多空白換成一個空白\n",
    "    \n",
    "    text = ' '.join([c for c in text.split() if c not in stop])    \n",
    "    text = ' '.join([c for c in text.split() if not c.isdigit()])\n",
    "    text = ' '.join([c for c in text.split() if c not in punctuation])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原始資料\n",
    "#train['doc_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 驗證資料處理\n",
    "#rm_tags(train['doc_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train['doc_text_cleaned'] = train.doc_text.apply(rm_tags)\n",
    "test['doc_text_cleaned'] = test.doc_text.apply(rm_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save to pickle done!!\n"
     ]
    }
   ],
   "source": [
    "train.to_pickle(\"./train.pkl\")\n",
    "test.to_pickle(\"./test.pkl\")\n",
    "print('Save to pickle done!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18687, 3), (18699, 3))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 驗證\n",
    "train_2, test_2 =  pd.read_pickle(\"./train.pkl\"),  pd.read_pickle(\"./test.pkl\")\n",
    "train_2.shape, test_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   row_id                                           doc_text  \\\n",
       " 0       0  84327 v2\\nThe findings, interpretations, and c...   \n",
       " 1       1                                                ...   \n",
       " 2       2                             78156\\n\\n\\n\\n\\nRisk...   \n",
       " \n",
       "                                     doc_text_cleaned  \n",
       " 0  v2 findings interpretations conclusions expres...  \n",
       " 1  decpg daily economics financial market comment...  \n",
       " 2  risk taking: corporate governance perspective ...  ,\n",
       "    row_id                                           doc_text  \\\n",
       " 0       0                                                ...   \n",
       " 1       1   EARLY LEARNING PARTNERSHIP\\n\\n\\n\\n\\n E L P\\n ...   \n",
       " 2       2                                                ...   \n",
       " \n",
       "                                     doc_text_cleaned  \n",
       " 0  roma inclusion smart economics illustrations b...  \n",
       " 1  early learning partnership e l p september ear...  \n",
       " 2  wps5739 policy research working paper entrepre...  )"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 驗證\n",
    "train_2[:3] , test_2[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 請刪除 不要的變數\n",
    "del train_2\n",
    "del test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = train_label.iloc[:, 1:].columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意這邊是前幾 N 筆\n",
    "# y 因為有row_id 要移除 所有 iloc[:, 1:]\n",
    "top = 100\n",
    "X, y = train['doc_text_cleaned'][:top] , train_label.iloc[:top, 1:]\n",
    "# X : Series\n",
    "# y : DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 準備建立模型 - 統計模型\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # 找出所有的單字\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # 加上權重\n",
    "from sklearn.linear_model import LogisticRegression # 多標籤分類\n",
    "from sklearn.pipeline import Pipeline # pipline上述的作業\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', OneVsRestClassifier(LogisticRegression(multi_class='ovr' , solver='sag'))  ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 OneVsRestClassifier(estimator=LogisticRegression(C=1.0,\n",
       "                                                                  class_weight=None,\n",
       "                                                                  dual=False,\n",
       "                                                                  fit_intercept=True,\n",
       "                                                                  intercept_scaling=1,\n",
       "                                                                  l1_ratio=None,\n",
       "                                                                  max_iter=100,\n",
       "                                                                  multi_class='ovr',\n",
       "                                                                  n_jobs=None,\n",
       "                                                                  penalty='l2',\n",
       "                                                                  random_state=None,\n",
       "                                                                  solver='sag',\n",
       "                                                                  tol=0.0001,\n",
       "                                                                  verbose=0,\n",
       "                                                                  warm_start=False),\n",
       "                                     n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 給資料進行訓練 Machine Learning - Statistics Model \n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.1\n",
      "                                            precision    recall  f1-score   support\n",
      "\n",
      "information_and_communication_technologies       0.00      0.00      0.00         3\n",
      "                                governance       0.00      0.00      0.00         0\n",
      "                         urban_development       0.00      0.00      0.00         0\n",
      "                       law_and_development       0.00      0.00      0.00         2\n",
      "                 public_sector_development       0.00      0.00      0.00         3\n",
      "                               agriculture       0.00      0.00      0.00         2\n",
      "         communities_and_human_settlements       0.00      0.00      0.00         0\n",
      "       health_and_nutrition_and_population       0.00      0.00      0.00         3\n",
      "                   culture_and_development       0.00      0.00      0.00         0\n",
      "              social_protections_and_labor       0.00      0.00      0.00         0\n",
      "         international_economics_and_trade       0.00      0.00      0.00         2\n",
      "                  conflict_and_development       0.00      0.00      0.00         0\n",
      "        science_and_technology_development       0.00      0.00      0.00         2\n",
      "                         rural_development       0.00      0.00      0.00         3\n",
      "                         poverty_reduction       0.00      0.00      0.00         4\n",
      "                        social_development       0.00      0.00      0.00         0\n",
      "                                 education       0.00      0.00      0.00         3\n",
      "                                 transport       0.00      0.00      0.00         0\n",
      "                                    gender       0.00      0.00      0.00         0\n",
      "      infrastructure_economics_and_finance       0.00      0.00      0.00         0\n",
      "                    energy_and_environment       0.00      0.00      0.00         3\n",
      "                   finance_and_development       0.80      0.67      0.73        12\n",
      "                 macroeconomics_and_growth       1.00      0.14      0.25        14\n",
      "                                     water       0.00      0.00      0.00         2\n",
      "\n",
      "                                 micro avg       0.83      0.17      0.29        58\n",
      "                                 macro avg       0.07      0.03      0.04        58\n",
      "                              weighted avg       0.41      0.17      0.21        58\n",
      "                               samples avg       0.40      0.22      0.26        58\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "prediction = pipeline.predict(X_test)\n",
    "#prediction , y_test.values.tolist()\n",
    "print('Test accuracy is {}'.format(accuracy_score(y_test.values, prediction)))\n",
    "\n",
    "report = metrics.classification_report(y_test, prediction, target_names=categories)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
