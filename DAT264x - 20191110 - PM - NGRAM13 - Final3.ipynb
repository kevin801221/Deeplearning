{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 套件\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from string import punctuation\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取 train data\n",
    "train = pd.read_csv('train_values.csv')\n",
    "train_label = pd.read_csv('train_labels.csv')\n",
    "test = pd.read_csv('test_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 檢查數據\n",
    "train.shape , train_label.shape, test.shape # 筆數正確"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拿高分的資料清除位置\n",
    "def rm_tags(text):\n",
    "    re_tag = r'<[^>]+>'\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 連字\n",
    "    text = re.sub(re_tag, '', text)\n",
    "    text = re.sub(r\"didn't\",\"did not\", text)\n",
    "    text = re.sub(r\"haven't\",\"have not\", text)\n",
    "    text = re.sub(r\"can't\",\"can not\", text)\n",
    "    text = re.sub(r\"it's\",\"it is\", text)\n",
    "    text = re.sub(r\"won't\",\"will not\", text)\n",
    "    text = re.sub(r\"wouldn't\",\"would not\",text)\n",
    "    text = re.sub(r\"what’s\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    \n",
    "    # remove non-ascii characters\n",
    "    text = ''.join(character for character in text if ord(character) < 128)    \n",
    "    \n",
    "    # 請繼續加入    \n",
    "    text = re.sub(r\"[&-/()),%']\", ' ', text) #這特殊符號都去除\n",
    "    text = re.sub(r\"\\.\", ' ', text) # 點換成一個空白\n",
    "    text = re.sub(r\"\\s+\", ' ', text) #多空白換成一個空白\n",
    "    \n",
    "    text = ' '.join([c for c in text.split() if c not in stop])    \n",
    "    text = ' '.join([c for c in text.split() if not c.isdigit()])\n",
    "    text = ' '.join([c for c in text.split() if c not in punctuation])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原始資料\n",
    "train['doc_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 驗證資料處理\n",
    "rm_tags(train['doc_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ********************************************************* 請注意\n",
    "train['doc_text_cleaned'] = train.doc_text.apply(rm_tags)\n",
    "test['doc_text_cleaned'] = test.doc_text.apply(rm_tags)\n",
    "#train, test =  pd.read_pickle(\"./train20191110.pkl\"),  pd.read_pickle(\"./test20191110.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 儲存已經清除完成數據 *********************************請注意\n",
    "train.to_pickle(\"./train20191110.pkl\")\n",
    "test.to_pickle(\"./test20191110.pkl\")\n",
    "print('Save to pickle done!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找出文字出現的頻率\n",
    "from nltk import FreqDist\n",
    "sample = train.loc[:1000, 'doc_text_cleaned']\n",
    "# for k in sample.values.tolist():\n",
    "#     for j in k.split():\n",
    "#         print(j)\n",
    "#[j for k in sample.values.tolist() for j in k.split() ]\n",
    "plt.figure(figsize=(16,6) )\n",
    "FreqDistSend = FreqDist( [j for k in sample.values.tolist() for j in k.split() ]  )\n",
    "FreqDistSend.plot(80)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = train_label.iloc[:, 1:].columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意這邊是前幾 N 筆\n",
    "# y 因為有row_id 要移除 所有 iloc[:, 1:]\n",
    "top = 100 #*************************************************************注意\n",
    "X, y = train['doc_text_cleaned'][:] , train_label.iloc[:, 1:]\n",
    "# X : Series\n",
    "# y : DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 準備建立模型 - 統計模型\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # 找出所有的單字\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # 加上權重\n",
    "from sklearn.feature_extraction.text import TfidfTransformer # 加上權重\n",
    "from sklearn.linear_model import LogisticRegression # 多標籤分類\n",
    "from sklearn.pipeline import Pipeline # pipline上述的作業\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "# *****************************ngram_range=(1, N) N可以是 3,4,5,6\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer( ngram_range=(1, 3)  )),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC(multi_class='ovr'))  ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 給資料進行訓練 Machine Learning - Statistics Model \n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "prediction = pipeline.predict(X_test)\n",
    "print('Test accuracy is {}'.format(accuracy_score(y_test.values, prediction)))\n",
    "\n",
    "report = metrics.classification_report(y_test, prediction, target_names=categories)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# 準備submission資料\n",
    "####################\n",
    "X_submission = test.doc_text_cleaned\n",
    "X_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預測資料  一定要全部\n",
    "prediction_test = pipeline.predict(X_submission[:])\n",
    "print(prediction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將預測結果轉換成csv\n",
    "print(prediction_test.shape)\n",
    "print(len(categories))\n",
    "final = pd.DataFrame(prediction_test, columns=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 匯出\n",
    "import os\n",
    "output = final.reset_index()\n",
    "output.columns =['row_id']+categories\n",
    "output.to_csv('submission_format_20191110_3.csv', sep=',', index=None)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析final submission\n",
    "plt.figure(figsize=(10,10))\n",
    "np.sum(final[categories] , axis=0).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
