{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import matplotlib as plt\n",
    "import util1 as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將圖片顯示出來, 每行 10 張圖, 最多 240 張圖\n",
    "# 參數依序為：圖片資料集,標籤資料集,開始顯示的索引,顯示的圖片數量,預測的答案資料集\n",
    "# 若 num 為 0 則顯示由 start 開始的全部圖片\n",
    "def showImgs(imgs, labs, start=0, num=0, predicts=[], by0123=True):\n",
    "    max_num = len(imgs)-start\n",
    "    if max_num > 240: max_num = 240  # 最多只顯示 240 張圖\n",
    "    if num <= 0 or num > max_num: num = max_num\n",
    "    plt.gcf().set_size_inches(16, 52 if len(predicts) else 40)\n",
    "    idx_list = get_idxs(imgs, labs, start, num, by0123)\n",
    "    for i in range(num):\n",
    "        ax = plt.subplot(24, 10, 1+i)\n",
    "        idx = idx_list[i]\n",
    "        ax.imshow(imgs[idx], cmap='gray_r',   #反白顯示 (白底黑字)\n",
    "                  norm=plt.Normalize(0.0, 255.0))  #指定灰階的範圍\n",
    "        if len(predicts):\n",
    "            title = 'label = ' + str(labs[idx])\n",
    "            if labs[idx] == predicts[idx]:\n",
    "                title += '\\npredi = ' + str(predicts[idx])\n",
    "            else:\n",
    "                title += '\\npre● = ' + str(predicts[idx])\n",
    "            ax.set_title(title, fontsize=13)\n",
    "        ax.set_xticks([]); ax.set_yticks([]) # X, Y 軸不顯示刻度\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x2880 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "\n",
    "adj_size = 0   # 指定要將數字調整為多少像素, 設為 0 表示不調整\n",
    "fns = ''        # 檔名附加訊息\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "u.showImgs(x_train, y_train, 0, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if adj_size > 0:\n",
    "    fns = '_S' + str(adj_size)\n",
    "    print(f'調整 MNIST 圖片的數字大小改為 {adj_size} 像素, 並置中')\n",
    "    import lab_mnist_util as u\n",
    "    for i in range(len(x_train)):\n",
    "        if i % 1000 == 0: print(i,end=',')\n",
    "        x_train[i] = u.img_best(x_train[i], size=adj_size, vdif=1, hdif=1)\n",
    "    for i in range(len(x_test)):\n",
    "        if i % 1000 == 0: print(i,end=',')\n",
    "        x_test[i] = u.img_best(x_test[i], size=adj_size, vdif=1, hdif=1)\n",
    "    u.showImgs(x_train, y_train, 0, 10)\n",
    "    print(f'\\n調整完成, 開始預處理及訓練模型...')\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# 預設理\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test  = keras.utils.to_categorical(y_test,  num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))  #0.25神經元暫停訓練不影響學習參數,但可避免overfitting\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))   #0.5神經元暫停訓練不影響學習參數,但可避免overfitting\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "model.summary() #Total params: 1,199,882"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 64s 1ms/sample - loss: 0.2349 - accuracy: 0.9291 - val_loss: 0.0524 - val_accuracy: 0.9834\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 64s 1ms/sample - loss: 0.0842 - accuracy: 0.9747 - val_loss: 0.0367 - val_accuracy: 0.9883\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 64s 1ms/sample - loss: 0.0643 - accuracy: 0.9804 - val_loss: 0.0343 - val_accuracy: 0.9888\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 64s 1ms/sample - loss: 0.0520 - accuracy: 0.9844 - val_loss: 0.0305 - val_accuracy: 0.9909\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 66s 1ms/sample - loss: 0.0427 - accuracy: 0.9867 - val_loss: 0.0315 - val_accuracy: 0.9888\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 64s 1ms/sample - loss: 0.0399 - accuracy: 0.9875 - val_loss: 0.0335 - val_accuracy: 0.9902\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 64s 1ms/sample - loss: 0.0336 - accuracy: 0.9895 - val_loss: 0.0252 - val_accuracy: 0.9926\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 64s 1ms/sample - loss: 0.0299 - accuracy: 0.9904 - val_loss: 0.0294 - val_accuracy: 0.9908\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 64s 1ms/sample - loss: 0.0276 - accuracy: 0.9913 - val_loss: 0.0291 - val_accuracy: 0.9912\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 64s 1ms/sample - loss: 0.0260 - accuracy: 0.9911 - val_loss: 0.0277 - val_accuracy: 0.9915\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 65s 1ms/sample - loss: 0.0214 - accuracy: 0.9929 - val_loss: 0.0309 - val_accuracy: 0.9917\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 64s 1ms/sample - loss: 0.0207 - accuracy: 0.9934 - val_loss: 0.0330 - val_accuracy: 0.9913\n",
      "對測試資料集的準確率： 0.9913\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))  #先不另外切validation出來直接用testing set\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('對測試資料集的準確率：', score[1])\n",
    "#對測試資料集的準確率： 0.9913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#程 將模型存檔\n",
    "model.save('模型_CNN' + fns + '_new.h5')   #← 將模型以指定的檔名存檔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
