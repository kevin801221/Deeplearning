{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Embedding layer is defined as the first hidden layer of a network. It must specify 3 arguments\n",
    "\n",
    "### input_dim: This is the size of the vocabulary in the text data. For example, if your data is integer encoded to values between 0-10, then the size of the vocabulary would be 11 words.\n",
    "### output_dim: This is the size of the vector space in which words will be embedded. It defines the size of the output vectors from this layer for each word. For example, it could be 32 or 100 or even larger. Test different values for your problem.\n",
    "### input_length: This is the length of input sequences, as you would define for any input layer of a Keras model. For example, if all of your input documents are comprised of 1000 words, this would be 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = []\n",
    "with open('glove.6B.100d.txt', encoding='utf-8') as f:\n",
    "    glove = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "glove_embedded = dict([ ( line.split()[0], np.array(line.split()[1:], dtype='float32') ) for line in glove])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.65059  ,  0.2016   ,  0.68666  ,  0.65851  , -0.29464  ,\n",
       "       -1.0846   ,  0.0052665, -0.35541  ,  0.69432  ,  0.58906  ,\n",
       "       -0.33003  ,  0.17822  ,  0.18632  ,  1.0461   ,  0.45654  ,\n",
       "        0.42563  ,  0.65376  , -0.089483 , -0.29322  ,  0.4492   ,\n",
       "        0.5301   , -0.33547  , -0.1022   , -1.0246   ,  1.0674   ,\n",
       "        0.79905  , -0.92671  , -0.10377  , -0.16778  , -0.037666 ,\n",
       "       -0.39318  , -0.12018  , -0.90603  ,  0.21761  ,  0.11231  ,\n",
       "        0.47103  , -0.23728  , -0.3534   ,  0.03686  , -0.82812  ,\n",
       "        0.41744  , -0.78007  , -0.36368  ,  0.1253   ,  1.1368   ,\n",
       "        0.13796  , -0.12501  , -0.19405  , -0.27672  , -0.061772 ,\n",
       "       -0.4815   , -0.027073 , -0.74655  ,  0.12224  , -0.73215  ,\n",
       "        1.15     ,  0.55559  , -0.078571 , -0.20306  , -0.0090857,\n",
       "       -0.38041  ,  0.85508  ,  0.25461  ,  0.044044 , -0.47575  ,\n",
       "       -0.84642  ,  0.41493  , -0.46109  ,  0.3211   ,  0.23407  ,\n",
       "       -0.077311 , -0.071668 ,  0.34068  ,  0.86601  , -0.77766  ,\n",
       "        0.58977  , -1.1875   , -0.26931  ,  0.81235  , -0.40009  ,\n",
       "        0.2417   ,  0.010831 , -0.45466  , -0.036616 ,  0.45868  ,\n",
       "       -0.36162  , -0.42561  , -0.18872  , -0.25526  , -0.80069  ,\n",
       "        0.14604  ,  0.62306  ,  0.55492  , -0.39533  ,  0.46959  ,\n",
       "       -0.23791  ,  0.46561  , -0.40697  ,  0.54547  , -0.069702 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_embedded.get('sashimi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7530954]\n",
      "[0.22298916]\n",
      "[0.68764853]\n",
      "[0.1912055]\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "glove_embedded['sushi'] , glove_embedded['sashimi']\n",
    "print(np.array(cosine_similarity(glove_embedded['sushi'].reshape(1,-1), glove_embedded['sashimi'].reshape(1,-1))).ravel())\n",
    "print(np.array(cosine_similarity(glove_embedded['sushi'].reshape(1,-1), glove_embedded['dumping'].reshape(1,-1))).ravel())\n",
    "print(np.array(cosine_similarity(glove_embedded['korea'].reshape(1,-1), glove_embedded['taiwan'].reshape(1,-1))).ravel())\n",
    "print(np.array(cosine_similarity(glove_embedded['ibm'].reshape(1,-1), glove_embedded['coffee'].reshape(1,-1))).ravel())\n",
    "print(np.array(cosine_similarity(glove_embedded['ibm'].reshape(1,-1), glove_embedded['ibm'].reshape(1,-1))).ravel())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
